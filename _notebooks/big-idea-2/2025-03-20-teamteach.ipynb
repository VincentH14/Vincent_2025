{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "categories: [CSP Big Idea 2]\n",
    "title: PopCorn Hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Idea 5.1 Beneficial and Harmful Effects of Computing Innovations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 1\n",
    "\n",
    "Positive: Chat GPT allows people to do a variety of tasks much more efficently and accuratley.\n",
    "Negative: Deepfake technology can lead to detrimental effects on people due to the spread of false information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 2\n",
    "\n",
    "Negative effects in technology is anything that harms societ in anyway due to technology. We can closesly mointor and plan out our projects and use respoonsible programming to avoid these mishaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 3\n",
    "\n",
    "Its important to udnerstand the uninteded consequnces of technology to make sure you dont fall into addiction with technology which could lead to harmful effects on you and others around you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hack 1\n",
    " A new use could be in wildlife conservation to track and protect endangered species. This could help monitor animal populations and prevent poaching, but it might also raise privacy concerns and be misused for tracking.\n",
    "\n",
    "## Homework Hack 2\n",
    "AI used in predictive policing can unfairly target marginalized communities. To fix this, developers could use diverse and unbiased data to train the AI and conduct regular audits to check for bias. Ethical AI development is important because it prevents discrimination and ensures fairness in decision-making.\n",
    "\n",
    "## Homework Hack 3\n",
    "Amazon’s hiring algorithm was created to select the best candidates, but it ended up discriminating against women. In response, Amazon stopped using the system after discovering the bias. To prevent this, developers should have tested the algorithm with diverse data to ensure fairness before using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 1: Example Problem in MCQ\n",
    "\n",
    "B. Designing new technologies to be accessible to individuals with different physical abilities\n",
    "\n",
    "D. Having world governments support the construction of network infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 2\n",
    "\n",
    "To address the digital divide, I would expand affordable internet access and provide devices to underserved communities while offering digital literacy training. Programs like the FCC's Affordable Connectivity Program (ACP) and local initiatives that distribute refurbished devices are already helping. To improve further, we could create community tech hubs in libraries and schools, offering hands-on workshops and mentorship to ensure equitable access and skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 1\n",
    "\n",
    "An example is the video game Grand Theft Auto V (GTA V), which often portrays minorities, especially Black and Latino characters, in stereotypical and violent roles. This bias may be caused by a lack of diversity in the game's development team, leading to the use of harmful stereotypes instead of accurate, nuanced representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 2\n",
    "\n",
    "I once tried using a voice assistant to search for a nearby restaurant, but it struggled to recognize my accent and kept giving me irrelevant results. It was frustrating because I had to repeat myself multiple times, and it felt like the technology wasn’t designed with diverse speech patterns in mind. One way to improve this would be to train the voice recognition system on a wider variety of accents and dialects to make it more inclusive for all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 3\n",
    "\n",
    "Bias could sneak into a fitness tracking app if the recommendations assume all users have the same physical abilities, fitness levels, or health conditions. For example, suggesting intense workouts might not be suitable for older adults or people with disabilities, making the app less effective or even harmful for them. To make the app fair and inclusive, I would add a personalized setup that asks about the user’s age, physical abilities, and health conditions to tailor recommendations. I would also include adaptive goals and alternative exercise suggestions to meet diverse needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hack\n",
    "\n",
    "I use YouTube regularly, and I’ve noticed that its recommendation algorithm often suggests similar types of content, which can create an echo chamber where I only see videos that reinforce my existing interests or viewpoints. This can limit exposure to diverse perspectives and make it harder for different voices to be heard. The bias might be caused by the algorithm prioritizing user engagement over content diversity, as it’s designed to show videos that will keep users watching longer. To reduce this bias, YouTube could introduce a “Discover New Perspectives” feature that recommends content from different viewpoints, cultures, and creators to promote a more balanced and inclusive experience."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

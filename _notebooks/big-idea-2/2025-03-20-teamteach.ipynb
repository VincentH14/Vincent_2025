{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "categories: [CSP Big Idea 2]\n",
    "title: PopCorn Hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Idea 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 1\n",
    "\n",
    "Positive: Chat GPT allows people to do a variety of tasks much more efficently and accuratley.\n",
    "Negative: Deepfake technology can lead to detrimental effects on people due to the spread of false information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 2\n",
    "\n",
    "Negative effects in technology is anything that harms societ in anyway due to technology. We can closesly mointor and plan out our projects and use respoonsible programming to avoid these mishaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack 3\n",
    "\n",
    "Its important to udnerstand the uninteded consequnces of technology to make sure you dont fall into addiction with technology which could lead to harmful effects on you and others around you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hack 1\n",
    " A new use could be in wildlife conservation to track and protect endangered species. This could help monitor animal populations and prevent poaching, but it might also raise privacy concerns and be misused for tracking.\n",
    "\n",
    "## Homework Hack 2\n",
    "AI used in predictive policing can unfairly target marginalized communities. To fix this, developers could use diverse and unbiased data to train the AI and conduct regular audits to check for bias. Ethical AI development is important because it prevents discrimination and ensures fairness in decision-making.\n",
    "\n",
    "## Homework Hack 3\n",
    "Amazonâ€™s hiring algorithm was created to select the best candidates, but it ended up discriminating against women. In response, Amazon stopped using the system after discovering the bias. To prevent this, developers should have tested the algorithm with diverse data to ensure fairness before using it.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
